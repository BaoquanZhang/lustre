Index: linux-2.6.9/fs/ext3/namei.c
===================================================================
--- linux-2.6.9.orig/fs/ext3/namei.c	2006-04-17 18:32:12.000000000 +0800
+++ linux-2.6.9/fs/ext3/namei.c	2006-04-23 21:40:41.000000000 +0800
@@ -24,6 +24,78 @@
  * 	Theodore Ts'o, 2002
  */
 
+/*
+ * iam: big theory statement.
+ *
+ * iam (Index Access Module) is a module providing abstraction of persistent
+ * transactional container on top of generalized ext3 htree.
+ *
+ * iam supports:
+ *
+ *     - key, pointer, and record size specifiable per container.
+ *
+ *     - trees taller than 2 index levels.
+ *
+ *     - read/write to existing ext3 htree directories as iam containers.
+ *
+ * iam container is a tree, consisting of leaf nodes containing keys and
+ * records stored in this container, and index nodes, containing keys and
+ * pointers to leaf or index nodes.
+ *
+ * iam does not work with keys directly, instead it calls user-supplied key
+ * comparison function (->dpo_keycmp()).
+ *
+ * Pointers are (currently) interpreted as logical offsets (measured in
+ * blocksful) within underlying flat file on top of which iam tree lives.
+ *
+ * On-disk format:
+ *
+ * iam mostly tries to reuse existing htree formats.
+ *
+ * Format of index node:
+ *
+ * +-----+-------+-------+-------+------+-------+------------+
+ * |     | count |       |       |      |       |            |
+ * | gap |   /   | entry | entry | .... | entry | free space |
+ * |     | limit |       |       |      |       |            |
+ * +-----+-------+-------+-------+------+-------+------------+
+ *
+ *       gap           this part of node is never accessed by iam code. It
+ *                     exists for binary compatibility with ext3 htree (that,
+ *                     in turn, stores fake struct ext2_dirent for ext2
+ *                     compatibility), and to keep some unspecified per-node
+ *                     data. Gap can be different for root and non-root index
+ *                     nodes. Gap size can be specified for each container
+ *                     (gap of 0 is allowed).
+ *
+ *       count/limit   current number of entries in this node, and the maximal
+ *                     number of entries that can fit into node. count/limit
+ *                     has the same size as entry, and is itself counted in
+ *                     count.
+ *
+ *       entry         index entry: consists of a key immediately followed by
+ *                     a pointer to a child node. Size of a key and size of a
+ *                     pointer depends on container. Entry has neither
+ *                     alignment nor padding.
+ *
+ *       free space    portion of node new entries are added to
+ *
+ * Entries in index node are sorted by their key value.
+ *
+ *
+ *
+ *
+ *
+ *
+ *
+ *
+ *
+ *
+ *
+ *
+ *
+ */
+
 #include <linux/fs.h>
 #include <linux/pagemap.h>
 #include <linux/jbd.h>
@@ -98,14 +170,6 @@
 	__le16 count;
 };
 
-struct dx_entry; /* incomplete type */
-struct dx_key;   /* incomplete type */
-
-struct dx_entry_compat {
-	__le32 hash;
-	__le32 block;
-};
-
 /*
  * dx_root_info is laid out so that if it should somehow get overlaid by a
  * dirent the two low bits of the hash version will be zero.  Therefore, the
@@ -135,111 +199,513 @@
 	struct {} entries[0];
 };
 
-
-struct dx_frame
-{
-	struct buffer_head *bh;
-	struct dx_entry *entries;
-	struct dx_entry *at;
-};
-
 struct dx_map_entry
 {
 	u32 hash;
 	u32 offs;
 };
 
-struct dx_path;
-struct dx_param {
-	size_t       dpo_key_size;
-	size_t       dpo_ptr_size;
-	size_t       dpo_node_gap;
-	size_t       dpo_root_gap;
-
-	u32 (*dpo_root_ptr)(struct dx_path *path);
-	int (*dpo_node_check)(struct dx_path *path,
-			      struct dx_frame *frame, void *cookie);
-	int (*dpo_node_init)(struct dx_path *path,
-			     struct buffer_head *bh, int root);
-	int (*dpo_keycmp)(struct dx_path *path,
-			  struct dx_key *k1, struct dx_key *k2);
+/*
+ * Entry within index tree node. Consists of a key immediately followed
+ * (without padding) by a pointer to the child node.
+ *
+ * Both key and pointer are of variable size, hence incomplete type.
+ */
+struct iam_entry;
+
+struct iam_entry_compat {
+	__le32 hash;
+	__le32 block;
+};
+
+/*
+ * Incomplete type used to refer to keys in iam container.
+ *
+ * As key size can be different from container to container, iam has to use
+ * incomplete type. Clients cast pointer to iam_key to real key type and back.
+ */
+struct iam_key;
+
+/* Incomplete type use to refer to the records stored in iam containers. */
+struct iam_rec;
+
+typedef __u64 iam_ptr_t;
+
+/*
+ * Index node traversed during tree lookup.
+ */
+struct iam_frame {
+	struct buffer_head *bh;    /* buffer holding node data */
+	struct iam_entry *entries; /* array of entries */
+	struct iam_entry *at;      /* target entry, found by binary search */
+};
+
+/* leaf node reached by tree lookup */
+struct iam_leaf {
+	struct buffer_head *bh;
+	struct iam_leaf_entry *entries;
+	struct iam_leaf_entry *at;
+};
+
+struct iam_path;
+struct iam_container;
+
+/*
+ * Parameters, describing a flavor of iam container.
+ */
+struct iam_descr {
+	/*
+	 * Size of a key in this container, in bytes.
+	 */
+ 	size_t       id_key_size;
+	/*
+	 * Size of a pointer to the next level (stored in index nodes), in
+	 * bytes.
+	 */
+	size_t       id_ptr_size;
+	/*
+	 * Size of a record (stored in leaf nodes), in bytes.
+	 */
+	size_t       id_rec_size;
+	/*
+	 * Size of unused (by iam) space at the beginning of every non-root
+	 * node, in bytes. Used for compatibility with ext3.
+	 */
+	size_t       id_node_gap;
+	/*
+	 * Size of unused (by iam) space at the beginning of root node, in
+	 * bytes. Used for compatibility with ext3.
+	 */
+	size_t       id_root_gap;
+
+	/*
+	 * Returns pointer (in the same sense as pointer in index entry) to
+	 * the root node.
+	 */
+	__u32 (*id_root_ptr)(struct iam_container *c);
+
+	/*
+	 * Check validity and consistency of index node. This is called when
+	 * iam just loaded new node into frame.
+	 */
+	int (*id_node_check)(struct iam_path *path, struct iam_frame *frame);
+	/*
+	 * Initialize new node (stored in @bh) that is going to be added into
+	 * tree.
+	 */
+	int (*id_node_init)(struct iam_container *c,
+			    struct buffer_head *bh, int root);
+	int (*id_node_read)(struct iam_container *c, iam_ptr_t ptr,
+			    handle_t *h, struct buffer_head **bh);
+	/*
+	 * Key comparison function. Returns -1, 0, +1.
+	 */
+	int (*id_keycmp)(struct iam_container *c,
+			 struct iam_key *k1, struct iam_key *k2);
+	/*
+	 * Create new container.
+	 *
+	 * Newly created container has a root node and a single leaf. Leaf
+	 * contains single record with the smallest possible key.
+	 */
+	int (*id_create)(struct iam_container *c);
+	struct {
+		/*
+		 * leaf operations.
+		 */
+		/*
+		 * returns true iff leaf is positioned at the last entry.
+		 */
+		int (*at_end)(struct iam_container *c, struct iam_leaf *l);
+		/* position leaf at the first entry */
+		void (*start)(struct iam_container *c, struct iam_leaf *l);
+		/* more leaf to the next entry. */
+		void (*next)(struct iam_container *c, struct iam_leaf *l);
+		/* return key of current leaf record in @k */
+		void (*key)(struct iam_container *c, struct iam_leaf *l,
+			    struct iam_key *k);
+		/* return pointer to entry body */
+		struct iam_rec *(*rec)(struct iam_container *c,
+				       struct iam_leaf *l);
+	} id_leaf;
+};
+
+struct iam_container {
+	/*
+	 * Underlying flat file. IO against this object is issued to
+	 * read/write nodes.
+	 */
+	struct inode     *ic_object;
+	/*
+	 * container flavor.
+	 */
+	struct iam_descr *ic_descr;
+	/*
+	 * pointer to flavor-specific per-container data.
+	 */
+	void             *ic_descr_data;
 };
 
 /*
  * Structure to keep track of a path drilled through htree.
  */
-struct dx_path {
-	struct inode         *dp_object;
-	struct dx_param      *dp_param;
-	int                   dp_indirect;
-	struct dx_frame       dp_frames[DX_MAX_TREE_HEIGHT];
-	struct dx_frame      *dp_frame;
-	struct dx_key        *dp_key_target;
-	struct dx_key        *dp_key_scratch[DX_SCRATCH_KEYS];
-};
-
-struct dx_path_compat {
-	struct dx_path dpc_path;
-	__u32          dpc_scrach[DX_SCRATCH_KEYS];
-};
-
-static u32 htree_root_ptr(struct dx_path *p);
-static int htree_node_check(struct dx_path *path,
-			    struct dx_frame *frame, void *cookie);
-static int htree_node_init(struct dx_path *path,
+struct iam_path {
+	/*
+	 * Parent container.
+	 */
+	struct iam_container  *ip_container;
+	/*
+	 * Number of index levels minus one.
+	 */
+	int                    ip_indirect;
+	/*
+	 * Nodes that top-to-bottom traversal passed through.
+	 */
+	struct iam_frame       ip_frames[DX_MAX_TREE_HEIGHT];
+	/*
+	 * Last filled frame in ->ip_frames. Refers to the 'twig' node (one
+	 * immediately above leaf).
+	 */
+	struct iam_frame      *ip_frame;
+	/*
+	 * Leaf node: a child of ->ip_frame.
+	 */
+	struct iam_leaf       *ip_leaf;
+	/*
+	 * Key searched for.
+	 */
+	struct iam_key        *ip_key_target;
+	/*
+	 * Scratch-pad area for temporary keys.
+	 */
+	struct iam_key        *ip_key_scratch[DX_SCRATCH_KEYS];
+	/*
+	 * pointer to flavor-specific per-container data.
+	 */
+	void                  *ip_descr_data;
+};
+
+/*
+ * Helper structure for legacy htrees.
+ */
+struct iam_path_compat {
+	struct iam_path      ipc_path;
+	struct iam_container ipc_container;
+	__u32                ipc_scrach[DX_SCRATCH_KEYS];
+};
+
+static u32 htree_root_ptr(struct iam_container *c);
+static int htree_node_check(struct iam_path *path, struct iam_frame *frame);
+static int htree_node_init(struct iam_container *c,
 			   struct buffer_head *bh, int root);
-static int htree_keycmp(struct dx_path *path,
-			struct dx_key *k1, struct dx_key *k2);
+static int htree_keycmp(struct iam_container *c,
+			struct iam_key *k1, struct iam_key *k2);
+static int htree_node_read(struct iam_container *c, iam_ptr_t ptr,
+			   handle_t *h, struct buffer_head **bh);
+
+/*
+ * Parameters describing iam compatibility mode in which existing ext3 htrees
+ * can be manipulated.
+ */
+static struct iam_descr htree_compat_param = {
+	.id_key_size = sizeof ((struct dx_map_entry *)NULL)->hash,
+	.id_ptr_size = sizeof ((struct dx_map_entry *)NULL)->offs,
+	.id_node_gap = offsetof(struct dx_node, entries),
+	.id_root_gap = offsetof(struct dx_root, entries),
+
+	.id_root_ptr   = htree_root_ptr,
+	.id_node_check = htree_node_check,
+	.id_node_init  = htree_node_init,
+	.id_node_read  = htree_node_read,
+	.id_keycmp     = htree_keycmp
+};
+
+
+struct iam_key;
+struct iam_rec;
+struct iam_descr;
+struct iam_container;
+struct iam_path;
 
-static struct dx_param htree_compat_param = {
-	.dpo_key_size = sizeof ((struct dx_map_entry *)NULL)->hash,
-	.dpo_ptr_size = sizeof ((struct dx_map_entry *)NULL)->offs,
-	.dpo_node_gap = offsetof(struct dx_node, entries),
-	.dpo_root_gap = offsetof(struct dx_root, entries),
-
-	.dpo_root_ptr   = htree_root_ptr,
-	.dpo_node_check = htree_node_check,
-	.dpo_node_init  = htree_node_init,
-	.dpo_keycmp     = htree_keycmp
+/*
+ * Initialize container @c, acquires additional reference on @inode.
+ */
+int iam_container_init(struct iam_container *c,
+		       struct iam_descr *descr, struct inode *inode);
+/*
+ * Finalize container @c, release all resources.
+ */
+void iam_container_fini(struct iam_container *c);
+
+/*
+ * Search container @c for record with key @k. If record is found, its data
+ * are moved into @r.
+ *
+ *
+ *
+ * Return values: +ve: found, 0: not-found, -ve: error
+ */
+int iam_lookup(struct iam_container *c, struct iam_key *k, struct iam_rec *r);
+/*
+ * Insert new record @r with key @k into container @c (within context of
+ * transaction @h.
+ *
+ * Return values: 0: success, -ve: error, including -EEXIST when record with
+ * given key is already present.
+ *
+ * postcondition: ergo(result == 0 || result == -EEXIST,
+ *                                  iam_lookup(c, k, r2) > 0 &&
+ *                                  !memcmp(r, r2, c->ic_descr->id_rec_size));
+ */
+int iam_insert(handle_t *h, struct iam_container *c,
+	       struct iam_key *k, struct iam_rec *r);
+/*
+ * Replace existing record with key @k, or insert new one. New record data are
+ * in @r.
+ *
+ * Return values: 0: success, -ve: error.
+ *
+ * postcondition: ergo(result == 0, iam_lookup(c, k, r2) > 0 &&
+ *                                  !memcmp(r, r2, c->ic_descr->id_rec_size));
+ */
+int iam_update(handle_t *h, struct iam_container *c,
+	       struct iam_key *k, struct iam_rec *r);
+/*
+ * Delete existing record with key @k.
+ *
+ * Return values: 0: success, -ENOENT: not-found, -ve: other error.
+ *
+ * postcondition: ergo(result == 0 || result == -ENOENT,
+ *                                 !iam_lookup(c, k, *));
+ */
+int iam_delete(handle_t *h, struct iam_container *c, struct iam_key *k);
+
+/*
+ * iam cursor (iterator) api.
+ */
+
+/*
+ * Flags controlling iterator functionality.
+ */
+enum iam_it_flags {
+	/*
+	 * this iterator will move (iam_it_{prev,next}() will be called on it)
+	 */
+	IAM_IT_MOVE  = (1 << 0),
+	/*
+	 * tree can be updated through this iterator.
+	 */
+	IAM_IT_WRITE = (1 << 1)
 };
 
+/*
+ * States of iterator state machine.
+ */
+enum iam_it_state {
+	/* initial state */
+	IAM_IT_DETACHED,
+	/* iterator is above particular record in the container */
+	IAM_IT_ATTACHED
+};
+
+/*
+ * Iterator.
+ *
+ * Immediately after call to iam_it_init() iterator is in "detached"
+ * (IAM_IT_DETACHED) state: it is associated with given parent container, but
+ * doesn't point to any particular record in this container.
+ *
+ * After successful call to iam_it_get() and until corresponding call to
+ * iam_it_put() iterator is in "attached" state (IAM_IT_ATTACHED).
+ *
+ * Attached iterator can move through records in a container (provided
+ * IAM_IT_MOVE permission) in a key order, can get record and key values as it
+ * passes over them, and can modify container (provided IAM_IT_WRITE
+ * permission).
+ *
+ * Concurrency: iterators are supposed to be local to thread. Interfaces below
+ * do no internal serialization.
+ *
+ */
+struct iam_iterator {
+	/*
+	 * iterator flags, taken from enum iam_it_flags.
+	 */
+	__u32                 ii_flags;
+	enum iam_it_state     ii_state;
+	/*
+	 * path to the record. Valid in IAM_IT_ATTACHED state.
+	 */
+	struct iam_path       ii_path;
+};
+
+static inline struct iam_key *keycpy(struct iam_container *c,
+				     struct iam_key *k1, struct iam_key *k2)
+{
+	return memcpy(k1, k2, c->ic_descr->id_key_size);
+}
+
+static inline int keycmp(struct iam_container *c,
+			 struct iam_key *k1, struct iam_key *k2)
+{
+	return c->ic_descr->id_keycmp(c, k1, k2);
+}
+
+static struct iam_container *iam_it_container(struct iam_iterator *it)
+{
+	return it->ii_path.ip_container;
+}
+
+static inline int it_keycmp(struct iam_iterator *it,
+			    struct iam_key *k1, struct iam_key *k2)
+{
+	return keycmp(iam_it_container(it), k1, k2);
+}
+
+/*
+ * Initialize iterator to IAM_IT_DETACHED state.
+ *
+ * postcondition: it_state(it) == IAM_IT_DETACHED
+ */
+int  iam_it_init(struct iam_iterator *it, struct iam_container *c, __u32 flags);
+/*
+ * Finalize iterator and release all resources.
+ *
+ * precondition: it_state(it) == IAM_IT_DETACHED
+ */
+void iam_it_fini(struct iam_iterator *it);
+
+/*
+ * Attach iterator. After successful completion, @it points to record with the
+ * largest key not larger than @k. Semantics of ->id_create() method guarantee
+ * that such record will always be found.
+ *
+ * Return value: 0: positioned on existing record,
+ *             -ve: error.
+ *
+ * precondition:  it_state(it) == IAM_IT_DETACHED
+ * postcondition: ergo(result == 0,
+ *                     (it_state(it) == IAM_IT_ATTACHED &&
+ *                      it_keycmp(it, iam_it_key_get(it, *), k) < 0))
+ */
+int iam_it_get(struct iam_iterator *it, struct iam_key *k);
+
+/*
+ * Duplicates iterator.
+ *
+ * postcondition: it_state(dst) == it_state(src) &&
+ *                iam_it_container(dst) == iam_it_container(src) &&
+ *                dst->ii_flags = src->ii_flags &&
+ *                ergo(it_state(it) == IAM_IT_ATTACHED,
+ *                     iam_it_rec_get(dst) == iam_it_rec_get(src) &&
+ *                     iam_it_key_get(dst, *1) == iam_it_key_get(src, *2))
+ */
+void iam_it_dup(struct iam_iterator *dst, struct iam_iterator *src);
+
+/*
+ * Detach iterator. Does nothing it detached state.
+ *
+ * postcondition: it_state(it) == IAM_IT_DETACHED
+ */
+void iam_it_put(struct iam_iterator *it);
+
+/*
+ * Move iterator one record right.
+ *
+ * Return value: 0: success,
+ *              +1: end of container reached
+ *             -ve: error
+ *
+ * precondition:  it_state(it) == IAM_IT_ATTACHED && it->ii_flags&IAM_IT_MOVE
+ * postcondition: ergo(result >= 0, it_state(it) == IAM_IT_ATTACHED)
+ */
+int iam_it_next(struct iam_iterator *it);
+
+/*
+ * Return pointer to the record under iterator.
+ *
+ * precondition:  it_state(it) == IAM_IT_ATTACHED
+ * postcondition: it_state(it) == IAM_IT_ATTACHED
+ */
+const struct iam_rec *iam_it_rec_get(struct iam_iterator *it);
+
+/*
+ * Replace contents of record under iterator.
+ *
+ * precondition:  it_state(it) == IAM_IT_ATTACHED && it->ii_flags&IAM_IT_WRITE
+ * postcondition: it_state(it) == IAM_IT_ATTACHED &&
+ *                ergo(result == 0, !memcmp(iam_it_rec_get(it), r, ...))
+ */
+int iam_it_rec_set(handle_t *h, struct iam_iterator *it, struct iam_rec *r);
+
+/*
+ * Place key under iterator in @k, return @k
+ *
+ * precondition:  it_state(it) == IAM_IT_ATTACHED
+ * postcondition: it_state(it) == IAM_IT_ATTACHED
+ */
+const struct iam_key *iam_it_key_get(struct iam_iterator *it,
+				     struct iam_key *k);
+
+/*
+ * Insert new record with key @k and contents from @r, shifting records to the
+ * right.
+ *
+ * precondition:  it_state(it) == IAM_IT_ATTACHED &&
+ *                it->ii_flags&IAM_IT_WRITE &&
+ *                it_keycmp(it, iam_it_key_get(it, *), k) < 0
+ * postcondition: it_state(it) == IAM_IT_ATTACHED &&
+ *                ergo(result == 0,
+ *                     it_keycmp(it, iam_it_key_get(it, *), k) == 0 &&
+ *                     !memcmp(iam_it_rec_get(it), r, ...))
+ */
+int iam_it_rec_insert(handle_t *h, struct iam_iterator *it,
+		      struct iam_key *k, struct iam_rec *r);
+/*
+ * Delete record under iterator.
+ *
+ * precondition:  it_state(it) == IAM_IT_ATTACHED && it->ii_flags&IAM_IT_WRITE
+ * postcondition: it_state(it) == IAM_IT_ATTACHED
+ */
+int iam_it_rec_delete(handle_t *h, struct iam_iterator *it);
 
 #ifdef CONFIG_EXT3_INDEX
-static inline unsigned dx_get_block(struct dx_path *p, struct dx_entry *entry);
-static void dx_set_block(struct dx_path *p,
-			 struct dx_entry *entry, unsigned value);
-static inline struct dx_key *dx_get_key(struct dx_path *p,
-					struct dx_entry *entry,
-					struct dx_key *key);
-static void dx_set_key(struct dx_path *p, struct dx_entry *entry,
-		       struct dx_key *key);
-static unsigned dx_get_count(struct dx_entry *entries);
-static unsigned dx_get_limit(struct dx_entry *entries);
-static void dx_set_count(struct dx_entry *entries, unsigned value);
-static void dx_set_limit(struct dx_entry *entries, unsigned value);
-static unsigned dx_root_limit(struct dx_path *p);
-static unsigned dx_node_limit(struct dx_path *p);
+static inline unsigned dx_get_block(struct iam_path *p, struct iam_entry *entry);
+static void dx_set_block(struct iam_path *p,
+			 struct iam_entry *entry, unsigned value);
+static inline struct iam_key *dx_get_key(struct iam_path *p,
+					struct iam_entry *entry,
+					struct iam_key *key);
+static void dx_set_key(struct iam_path *p, struct iam_entry *entry,
+		       struct iam_key *key);
+static unsigned dx_get_count(struct iam_entry *entries);
+static unsigned dx_get_limit(struct iam_entry *entries);
+static void dx_set_count(struct iam_entry *entries, unsigned value);
+static void dx_set_limit(struct iam_entry *entries, unsigned value);
+static unsigned dx_root_limit(struct iam_path *p);
+static unsigned dx_node_limit(struct iam_path *p);
 static int dx_probe(struct dentry *dentry,
 		    struct inode *dir,
 		    struct dx_hash_info *hinfo,
-		    struct dx_path *path);
+		    struct iam_path *path);
 static int dx_make_map (struct ext3_dir_entry_2 *de, int size,
 			struct dx_hash_info *hinfo, struct dx_map_entry map[]);
 static void dx_sort_map(struct dx_map_entry *map, unsigned count);
 static struct ext3_dir_entry_2 *dx_move_dirents (char *from, char *to,
 		struct dx_map_entry *offsets, int count);
 static struct ext3_dir_entry_2* dx_pack_dirents (char *base, int size);
-static void dx_insert_block (struct dx_path *path,
-			     struct dx_frame *frame, u32 hash, u32 block);
+static void dx_insert_block (struct iam_path *path,
+			     struct iam_frame *frame, u32 hash, u32 block);
 static int ext3_htree_next_block(struct inode *dir, __u32 hash,
-				 struct dx_path *path, __u32 *start_hash);
+				 struct iam_path *path, __u32 *start_hash);
 static struct buffer_head * ext3_dx_find_entry(struct dentry *dentry,
 		       struct ext3_dir_entry_2 **res_dir, int *err);
 static int ext3_dx_add_entry(handle_t *handle, struct dentry *dentry,
 			     struct inode *inode);
 
-static inline void dx_path_init(struct dx_path *path, struct inode *inode);
-static inline void dx_path_fini(struct dx_path *path);
+static inline void iam_path_init(struct iam_path *path,
+				 struct iam_container *c);
+static inline void iam_path_fini(struct iam_path *path);
 
 
 /*
@@ -247,153 +713,154 @@
  * Mask them off for now.
  */
 
-static inline void *entry_off(struct dx_entry *entry, ptrdiff_t off)
+static inline void *entry_off(struct iam_entry *entry, ptrdiff_t off)
 {
 	return (void *)((char *)entry + off);
 }
 
-static inline size_t dx_entry_size(struct dx_path *p)
+static inline struct iam_descr *path_descr(struct iam_path *p)
 {
-	return p->dp_param->dpo_key_size + p->dp_param->dpo_ptr_size;
+	return p->ip_container->ic_descr;
 }
 
-static inline struct dx_entry *dx_entry_shift(struct dx_path *p,
-					      struct dx_entry *entry, int shift)
+static inline struct inode *path_obj(struct iam_path *p)
+{
+	return p->ip_container->ic_object;
+}
+
+static inline size_t iam_entry_size(struct iam_path *p)
+{
+	return path_descr(p)->id_key_size + path_descr(p)->id_ptr_size;
+}
+
+static inline struct iam_entry *iam_entry_shift(struct iam_path *p,
+					      struct iam_entry *entry, int shift)
 {
 	void *e = entry;
-	return e + shift * dx_entry_size(p);
+	return e + shift * iam_entry_size(p);
 }
 
-static inline ptrdiff_t dx_entry_diff(struct dx_path *p,
-				      struct dx_entry *e1, struct dx_entry *e2)
+static inline ptrdiff_t iam_entry_diff(struct iam_path *p,
+				      struct iam_entry *e1, struct iam_entry *e2)
 {
 	ptrdiff_t diff;
 
 	diff = (void *)e1 - (void *)e2;
-	assert(diff / dx_entry_size(p) * dx_entry_size(p) == diff);
-	return diff / dx_entry_size(p);
+	assert(diff / iam_entry_size(p) * iam_entry_size(p) == diff);
+	return diff / iam_entry_size(p);
 }
 
-static inline unsigned dx_get_block(struct dx_path *p, struct dx_entry *entry)
+static inline unsigned dx_get_block(struct iam_path *p, struct iam_entry *entry)
 {
-	return le32_to_cpu(*(u32 *)entry_off(entry, p->dp_param->dpo_key_size))
+	return le32_to_cpu(*(u32 *)entry_off(entry, path_descr(p)->id_key_size))
 		& 0x00ffffff;
 }
 
-static inline void dx_set_block(struct dx_path *p,
-				struct dx_entry *entry, unsigned value)
+static inline void dx_set_block(struct iam_path *p,
+				struct iam_entry *entry, unsigned value)
 {
-	*(u32*)entry_off(entry, p->dp_param->dpo_key_size) = cpu_to_le32(value);
+	*(u32*)entry_off(entry,
+			 path_descr(p)->id_key_size) = cpu_to_le32(value);
 }
 
-static inline struct dx_key *dx_get_key(struct dx_path *p,
-					struct dx_entry *entry,
-					struct dx_key *key)
+static inline struct iam_key *dx_get_key(struct iam_path *p,
+					struct iam_entry *entry,
+					struct iam_key *key)
 {
-	memcpy(key, entry, p->dp_param->dpo_key_size);
+	memcpy(key, entry, path_descr(p)->id_key_size);
 	return key;
 }
 
-static inline struct dx_key *dx_key_at(struct dx_path *p,
-				       struct dx_entry *entry)
+static inline struct iam_key *iam_key_at(struct iam_path *p,
+				       struct iam_entry *entry)
 {
-	return (struct dx_key *)entry;
+	return (struct iam_key *)entry;
 }
 
-static inline void dx_set_key(struct dx_path *p,
-			      struct dx_entry *entry, struct dx_key *key)
+static inline void dx_set_key(struct iam_path *p,
+			      struct iam_entry *entry, struct iam_key *key)
 {
-	memcpy(entry, key, p->dp_param->dpo_key_size);
+	memcpy(entry, key, path_descr(p)->id_key_size);
 }
 
-static inline unsigned dx_get_count (struct dx_entry *entries)
+static inline unsigned dx_get_count (struct iam_entry *entries)
 {
 	return le16_to_cpu(((struct dx_countlimit *) entries)->count);
 }
 
-static inline unsigned dx_get_limit (struct dx_entry *entries)
+static inline unsigned dx_get_limit (struct iam_entry *entries)
 {
 	return le16_to_cpu(((struct dx_countlimit *) entries)->limit);
 }
 
-static inline void dx_set_count (struct dx_entry *entries, unsigned value)
+static inline void dx_set_count (struct iam_entry *entries, unsigned value)
 {
 	((struct dx_countlimit *) entries)->count = cpu_to_le16(value);
 }
 
-static inline void dx_set_limit (struct dx_entry *entries, unsigned value)
+static inline void dx_set_limit (struct iam_entry *entries, unsigned value)
 {
 	((struct dx_countlimit *) entries)->limit = cpu_to_le16(value);
 }
 
-static inline unsigned dx_root_limit(struct dx_path *p)
+static inline unsigned dx_root_limit(struct iam_path *p)
 {
-	struct dx_param *param = p->dp_param;
-	unsigned entry_space   = p->dp_object->i_sb->s_blocksize -
-		param->dpo_root_gap;
-	return entry_space / (param->dpo_key_size + param->dpo_ptr_size);
+	struct iam_descr *param = path_descr(p);
+	unsigned entry_space = path_obj(p)->i_sb->s_blocksize -
+		param->id_root_gap;
+	return entry_space / (param->id_key_size + param->id_ptr_size);
 }
 
-static inline unsigned dx_node_limit(struct dx_path *p)
+static inline unsigned dx_node_limit(struct iam_path *p)
 {
-	struct dx_param *param = p->dp_param;
-	unsigned entry_space   = p->dp_object->i_sb->s_blocksize -
-		param->dpo_node_gap;
-	return entry_space / (param->dpo_key_size + param->dpo_ptr_size);
+	struct iam_descr *param = path_descr(p);
+	unsigned entry_space   = path_obj(p)->i_sb->s_blocksize -
+		param->id_node_gap;
+	return entry_space / (param->id_key_size + param->id_ptr_size);
 }
 
-static inline int dx_index_is_compat(struct dx_path *path)
+static inline int dx_index_is_compat(struct iam_path *path)
 {
-	return path->dp_param == &htree_compat_param;
+	return path_descr(path) == &htree_compat_param;
 }
 
-static struct dx_entry *dx_get_entries(struct dx_path *path, void *data,
+static struct iam_entry *dx_get_entries(struct iam_path *path, void *data,
 				       int root)
 {
 	return data +
 		(root ?
-		 path->dp_param->dpo_root_gap : path->dp_param->dpo_node_gap);
+		 path_descr(path)->id_root_gap : path_descr(path)->id_node_gap);
 }
 
-static struct dx_entry *dx_node_get_entries(struct dx_path *path,
-					    struct dx_frame *frame)
+static struct iam_entry *dx_node_get_entries(struct iam_path *path,
+					    struct iam_frame *frame)
 {
 	return dx_get_entries(path,
-			      frame->bh->b_data, frame == path->dp_frames);
-}
-
-static inline struct dx_key *keycpy(struct dx_path *p,
-				    struct dx_key *k1, struct dx_key *k2)
-{
-	return memcpy(k1, k2, p->dp_param->dpo_key_size);
-}
-
-static inline int keycmp(struct dx_path *p,
-			 struct dx_key *k1, struct dx_key *k2)
-{
-	return p->dp_param->dpo_keycmp(p, k1, k2);
+			      frame->bh->b_data, frame == path->ip_frames);
 }
 
-static int dx_node_check(struct dx_path *p, struct dx_frame *f)
+static int dx_node_check(struct iam_path *p, struct iam_frame *f)
 {
-	struct dx_entry *e;
+	struct iam_entry     *e;
+	struct iam_container *c;
 	unsigned count;
 	unsigned  i;
 
+	c = p->ip_container;
 	e = dx_node_get_entries(p, f);
 	count = dx_get_count(e);
-	e = dx_entry_shift(p, e, 1);
-	for (i = 0; i < count - 1; ++i, e = dx_entry_shift(p, e, 1)) {
-		keycpy(p, p->dp_key_scratch[0], p->dp_key_scratch[1]);
-		dx_get_key(p, e, p->dp_key_scratch[1]);
+	e = iam_entry_shift(p, e, 1);
+	for (i = 0; i < count - 1; ++i, e = iam_entry_shift(p, e, 1)) {
+		keycpy(c, p->ip_key_scratch[0], p->ip_key_scratch[1]);
+		dx_get_key(p, e, p->ip_key_scratch[1]);
 		if (i > 0 &&
-		    keycmp(p, p->dp_key_scratch[0], p->dp_key_scratch[1]) > 0)
+		    keycmp(c, p->ip_key_scratch[0], p->ip_key_scratch[1]) > 0)
 			return 0;
 	}
 	return 1;
 }
 
-static u32 htree_root_ptr(struct dx_path *path)
+static u32 htree_root_ptr(struct iam_container *c)
 {
 	return 0;
 }
@@ -403,20 +870,19 @@
 	struct dentry       *dentry;
 };
 
-static int htree_node_check(struct dx_path *path, struct dx_frame *frame,
-			    void *cookie)
+static int htree_node_check(struct iam_path *path, struct iam_frame *frame)
 {
 	void *data;
-	struct dx_entry *entries;
+	struct iam_entry *entries;
 	struct super_block *sb;
 
 	data = frame->bh->b_data;
 	entries = dx_node_get_entries(path, frame);
-	sb = path->dp_object->i_sb;
-	if (frame == path->dp_frames) {
+	sb = path_obj(path)->i_sb;
+	if (frame == path->ip_frames) {
 		/* root node */
 		struct dx_root *root;
-		struct htree_cookie *hc = cookie;
+		struct htree_cookie *hc = path->ip_descr_data;
 
 		root = data;
 		if (root->info.hash_version > DX_HASH_MAX) {
@@ -433,8 +899,8 @@
 			return ERR_BAD_DX_DIR;
 		}
 
-		path->dp_indirect = root->info.indirect_levels;
-		if (path->dp_indirect > DX_MAX_TREE_HEIGHT - 1) {
+		path->ip_indirect = root->info.indirect_levels;
+		if (path->ip_indirect > DX_MAX_TREE_HEIGHT - 1) {
 			ext3_warning(sb, __FUNCTION__,
 				     "Unimplemented inode hash depth: %#06x",
 				     root->info.indirect_levels);
@@ -450,17 +916,17 @@
 		if (hc->dentry)
 			ext3fs_dirhash(hc->dentry->d_name.name,
 				       hc->dentry->d_name.len, hc->hinfo);
-		path->dp_key_target = (struct dx_key *)&hc->hinfo->hash;
+		path->ip_key_target = (struct iam_key *)&hc->hinfo->hash;
 	} else {
 		/* non-root index */
-		assert(entries == data + path->dp_param->dpo_node_gap);
+		assert(entries == data + path_descr(path)->id_node_gap);
 		assert(dx_get_limit(entries) == dx_node_limit(path));
 	}
 	frame->entries = frame->at = entries;
 	return 0;
 }
 
-static int htree_node_init(struct dx_path *path,
+static int htree_node_init(struct iam_container *c,
 			   struct buffer_head *bh, int root)
 {
 	struct dx_node *node;
@@ -468,13 +934,24 @@
 	assert(!root);
 
 	node = (void *)bh->b_data;
-	node->fake.rec_len = cpu_to_le16(path->dp_object->i_sb->s_blocksize);
+	node->fake.rec_len = cpu_to_le16(c->ic_object->i_sb->s_blocksize);
 	node->fake.inode = 0;
 	return 0;
 }
 
-static int htree_keycmp(struct dx_path *path,
-			struct dx_key *k1, struct dx_key *k2)
+static int htree_node_read(struct iam_container *c, iam_ptr_t ptr,
+			   handle_t *handle, struct buffer_head **bh)
+{
+	int result = 0;
+
+	*bh = ext3_bread(handle, c->ic_object, (int)ptr, 0, &result);
+	if (*bh == NULL)
+		result = -EIO;
+	return result;
+}
+
+static int htree_keycmp(struct iam_container *c,
+			struct iam_key *k1, struct iam_key *k2)
 {
 	__u32 p1 = le32_to_cpu(*(__u32 *)k1);
 	__u32 p2 = le32_to_cpu(*(__u32 *)k2);
@@ -486,7 +963,7 @@
  * Debug
  */
 #ifdef DX_DEBUG
-static void dx_show_index (char * label, struct dx_entry *entries)
+static void dx_show_index (char * label, struct iam_entry *entries)
 {
         int i, n = dx_get_count (entries);
         printk("%s index ", label);
@@ -535,7 +1012,7 @@
 }
 
 struct stats dx_show_entries(struct dx_hash_info *hinfo, struct inode *dir,
-			     struct dx_entry *entries, int levels)
+			     struct iam_entry *entries, int levels)
 {
 	unsigned blocksize = dir->i_sb->s_blocksize;
 	unsigned count = dx_get_count (entries), names = 0, space = 0, i;
@@ -565,32 +1042,33 @@
 }
 #endif /* DX_DEBUG */
 
-static int dx_lookup(struct dx_path *path, void *cookie)
+static int dx_lookup(struct iam_path *path)
 {
 	u32 ptr;
-	int err;
+	int err = 0;
 	int i;
 
-	struct dx_param *param;
-	struct dx_frame *frame;
-
-	param = path->dp_param;
+	struct iam_descr *param;
+	struct iam_frame *frame;
+	struct iam_container *c;
 
-	for (frame = path->dp_frames, i = 0,
-	     ptr = param->dpo_root_ptr(path); i <= path->dp_indirect;
+	param = path_descr(path);
+	c = path->ip_container;
+	
+	for (frame = path->ip_frames, i = 0,
+		     ptr = param->id_root_ptr(path->ip_container);
+	     i <= path->ip_indirect;
 	     ptr = dx_get_block(path, frame->at), ++frame, ++i) {
-		struct dx_entry *entries;
-		struct dx_entry *p;
-		struct dx_entry *q;
-		struct dx_entry *m;
+		struct iam_entry *entries;
+		struct iam_entry *p;
+		struct iam_entry *q;
+		struct iam_entry *m;
 		unsigned count;
 
-		frame->bh = ext3_bread(NULL, path->dp_object, ptr, 0, &err);
-		if (frame->bh == NULL) {
-			err = -EIO;
+		err = param->id_node_read(c, (iam_ptr_t)ptr, NULL, &frame->bh);
+		if (err != 0)
 			break;
-		}
-		err = param->dpo_node_check(path, frame, cookie);
+		err = param->id_node_check(path, frame);
 		if (err != 0)
 			break;
 
@@ -599,37 +1077,37 @@
 		entries = frame->entries;
 		count = dx_get_count(entries);
 		assert(count && count <= dx_get_limit(entries));
-		p = dx_entry_shift(path, entries, 1);
-		q = dx_entry_shift(path, entries, count - 1);
+		p = iam_entry_shift(path, entries, 1);
+		q = iam_entry_shift(path, entries, count - 1);
 		while (p <= q) {
-			m = dx_entry_shift(path,
-					   p, dx_entry_diff(path, q, p) / 2);
+			m = iam_entry_shift(path,
+					   p, iam_entry_diff(path, q, p) / 2);
 			dxtrace(printk("."));
-			if (keycmp(path, dx_key_at(path, m),
-				   path->dp_key_target) > 0)
-				q = dx_entry_shift(path, m, -1);
+			if (keycmp(c, iam_key_at(path, m),
+				   path->ip_key_target) > 0)
+				q = iam_entry_shift(path, m, -1);
 			else
-				p = dx_entry_shift(path, m, +1);
+				p = iam_entry_shift(path, m, +1);
 		}
 
-		frame->at = dx_entry_shift(path, p, -1);
+		frame->at = iam_entry_shift(path, p, -1);
 		if (1) { // linear search cross check
 			unsigned n = count - 1;
-			struct dx_entry *at;
+			struct iam_entry *at;
 
 			at = entries;
 			while (n--) {
 				dxtrace(printk(","));
-				at = dx_entry_shift(path, at, +1);
-				if (keycmp(path, dx_key_at(path, at),
-					   path->dp_key_target) > 0) {
-					if (at != dx_entry_shift(path, frame->at, 1)) {
+				at = iam_entry_shift(path, at, +1);
+				if (keycmp(c, iam_key_at(path, at),
+					   path->ip_key_target) > 0) {
+					if (at != iam_entry_shift(path, frame->at, 1)) {
 						BREAKPOINT;
 						printk(KERN_EMERG "%i\n",
-						       keycmp(path, dx_key_at(path, at),
-							      path->dp_key_target));
+						       keycmp(c, iam_key_at(path, at),
+							      path->ip_key_target));
 					}
-					at = dx_entry_shift(path, at, -1);
+					at = iam_entry_shift(path, at, -1);
 					break;
 				}
 			}
@@ -637,8 +1115,8 @@
 		}
 	}
 	if (err != 0)
-		dx_path_fini(path);
-	path->dp_frame = --frame;
+		iam_path_fini(path);
+	path->ip_frame = --frame;
 	return err;
 }
 
@@ -652,7 +1130,7 @@
  * back to userspace.
  */
 static int dx_probe(struct dentry *dentry, struct inode *dir,
-		    struct dx_hash_info *hinfo, struct dx_path *path)
+		    struct dx_hash_info *hinfo, struct iam_path *path)
 {
 	int err;
 	struct htree_cookie hc = {
@@ -661,39 +1139,78 @@
 	};
 
 	assert(dx_index_is_compat(path));
-	err = dx_lookup(path, &hc);
-	assert(err != 0 || path->dp_frames[path->dp_indirect].bh != NULL);
+	path->ip_descr_data = &hc;
+	err = dx_lookup(path);
+	assert(err != 0 || path->ip_frames[path->ip_indirect].bh != NULL);
 	return err;
 }
 
-static inline void dx_path_init(struct dx_path *path, struct inode *inode)
+/*
+ * Initialize container @c, acquires additional reference on @inode.
+ */
+int iam_container_init(struct iam_container *c,
+		       struct iam_descr *descr, struct inode *inode)
+{
+	memset(c, 0, sizeof *c);
+	c->ic_descr  = descr;
+	c->ic_object = igrab(inode);
+	if (c->ic_object != NULL)
+		return 0;
+	else
+		return -ENOENT;
+}
+
+/*
+ * Finalize container @c, release all resources.
+ */
+void iam_container_fini(struct iam_container *c)
+{
+	if (c->ic_object != NULL) {
+		iput(c->ic_object);
+		c->ic_object = NULL;
+	}
+}
+
+static inline void iam_path_init(struct iam_path *path, struct iam_container *c)
 {
 	memset(path, 0, sizeof *path);
-	path->dp_object = inode;
-	path->dp_frame = path->dp_frames;
+	path->ip_container = c;
+	path->ip_frame = path->ip_frames;
 }
 
-static inline void dx_path_fini(struct dx_path *path)
+static inline void iam_path_fini(struct iam_path *path)
 {
 	int i;
 
-	for (i = 0; i < ARRAY_SIZE(path->dp_frames); i++) {
-		if (path->dp_frames[i].bh != NULL) {
-			brelse(path->dp_frames[i].bh);
-			path->dp_frames[i].bh = NULL;
+	for (i = 0; i < ARRAY_SIZE(path->ip_frames); i++) {
+		if (path->ip_frames[i].bh != NULL) {
+			brelse(path->ip_frames[i].bh);
+			path->ip_frames[i].bh = NULL;
 		}
 	}
 }
 
-static void dx_path_compat_init(struct dx_path_compat *path,
-				struct inode *inode)
+static void iam_path_compat_init(struct iam_path_compat *path,
+				 struct inode *inode)
 {
 	int i;
-	dx_path_init(&path->dpc_path, inode);
-	path->dpc_path.dp_param = &htree_compat_param;
-	for (i = 0; i < ARRAY_SIZE(path->dpc_path.dp_key_scratch); ++i)
-		path->dpc_path.dp_key_scratch[i] =
-			(struct dx_key *)&path->dpc_scrach[i];
+
+	iam_container_init(&path->ipc_container, &htree_compat_param, inode);
+	/*
+	 * XXX hack allowing finalization of iam_path_compat with
+	 * iam_path_fini().
+	 */
+	iput(inode);
+	iam_path_init(&path->ipc_path, &path->ipc_container);
+	for (i = 0; i < ARRAY_SIZE(path->ipc_path.ip_key_scratch); ++i)
+		path->ipc_path.ip_key_scratch[i] =
+			(struct iam_key *)&path->ipc_scrach[i];
+}
+
+static void iam_path_compat_fini(struct iam_path_compat *path)
+{
+	iam_path_fini(&path->ipc_path);
+	iam_container_fini(&path->ipc_container);
 }
 
 /*
@@ -714,16 +1231,16 @@
  * hash of the next page.
  */
 static int ext3_htree_next_block(struct inode *dir, __u32 hash,
-				 struct dx_path *path, __u32 *start_hash)
+				 struct iam_path *path, __u32 *start_hash)
 {
-	struct dx_frame *p;
+	struct iam_frame *p;
 	struct buffer_head *bh;
 	int err, num_frames = 0;
 	__u32 bhash;
 
 	assert(dx_index_is_compat(path));
 
-	p = path->dp_frame;
+	p = path->ip_frame;
 	/*
 	 * Find the next leaf page by incrementing the frame pointer.
 	 * If we run out of entries in the interior node, loop around and
@@ -732,11 +1249,11 @@
 	 * nodes need to be read.
 	 */
 	while (1) {
-		p->at = dx_entry_shift(path, p->at, +1);
-		if (p->at < dx_entry_shift(path, p->entries,
+		p->at = iam_entry_shift(path, p->at, +1);
+		if (p->at < iam_entry_shift(path, p->entries,
 					   dx_get_count(p->entries)))
 			break;
-		if (p == path->dp_frames)
+		if (p == path->ip_frames)
 			return 0;
 		num_frames++;
 		--p;
@@ -749,7 +1266,7 @@
 	 * desired contiuation hash.  If it doesn't, return since
 	 * there's no point to read in the successive index pages.
 	 */
-	dx_get_key(path, p->at, (struct dx_key *)&bhash);
+	dx_get_key(path, p->at, (struct iam_key *)&bhash);
 	if (start_hash)
 		*start_hash = bhash;
 	if ((hash & 1) == 0) {
@@ -761,8 +1278,10 @@
 	 * block so no check is necessary
 	 */
 	while (num_frames--) {
-		if (!(bh = ext3_bread(NULL, dir,
-				      dx_get_block(path, p->at), 0, &err)))
+		err = path_descr(path)->id_node_read(path->ip_container,
+						     (iam_ptr_t)dx_get_block(path, p->at),
+						     NULL, &bh);
+		if (err != 0)
 			return err; /* Failure */
 		++p;
 		brelse (p->bh);
@@ -837,8 +1356,8 @@
 {
 	struct dx_hash_info hinfo;
 	struct ext3_dir_entry_2 *de;
-	struct dx_path_compat cpath;
-	struct dx_path *path = &cpath.dpc_path;
+	struct iam_path_compat cpath;
+	struct iam_path *path = &cpath.ipc_path;
 	struct inode *dir;
 	int block, err;
 	int count = 0;
@@ -848,7 +1367,7 @@
 	dxtrace(printk("In htree_fill_tree, start hash: %x:%x\n", start_hash,
 		       start_minor_hash));
 	dir = dir_file->f_dentry->d_inode;
-	dx_path_compat_init(&cpath, dir);
+	iam_path_compat_init(&cpath, dir);
 	if (!(EXT3_I(dir)->i_flags & EXT3_INDEX_FL)) {
 		hinfo.hash_version = EXT3_SB(dir->i_sb)->s_def_hash_version;
 		hinfo.seed = EXT3_SB(dir->i_sb)->s_hash_seed;
@@ -865,7 +1384,7 @@
 
 	/* Add '.' and '..' from the htree header */
 	if (!start_hash && !start_minor_hash) {
-		de = (struct ext3_dir_entry_2 *) path->dp_frames[0].bh->b_data;
+		de = (struct ext3_dir_entry_2 *) path->ip_frames[0].bh->b_data;
 		if ((err = ext3_htree_store_dirent(dir_file, 0, 0, de)) != 0)
 			goto errout;
 		de = ext3_next_entry(de);
@@ -875,7 +1394,7 @@
 	}
 
 	while (1) {
-		block = dx_get_block(path, path->dp_frame->at);
+		block = dx_get_block(path, path->ip_frame->at);
 		ret = htree_dirblock_to_tree(dir_file, dir, block, &hinfo,
 					     start_hash, start_minor_hash);
 		if (ret < 0) {
@@ -900,12 +1419,12 @@
 		    (count && ((hashval & 1) == 0)))
 			break;
 	}
-	dx_path_fini(path);
+	iam_path_fini(path);
 	dxtrace(printk("Fill tree: returned %d entries, next hash: %x\n",
 		       count, *next_hash));
 	return count;
 errout:
-	dx_path_fini(path);
+	iam_path_fini(path);
 	return (err);
 }
 
@@ -964,18 +1483,18 @@
 	} while(more);
 }
 
-static void dx_insert_block(struct dx_path *path,
-			    struct dx_frame *frame, u32 hash, u32 block)
+static void dx_insert_block(struct iam_path *path,
+			    struct iam_frame *frame, u32 hash, u32 block)
 {
-	struct dx_entry *entries = frame->entries;
-	struct dx_entry *old = frame->at, *new = dx_entry_shift(path, old, +1);
+	struct iam_entry *entries = frame->entries;
+	struct iam_entry *old = frame->at, *new = iam_entry_shift(path, old, +1);
 	int count = dx_get_count(entries);
 
 	assert(count < dx_get_limit(entries));
-	assert(old < dx_entry_shift(path, entries, count));
-	memmove(dx_entry_shift(path, new, 1), new,
-		(char *)dx_entry_shift(path, entries, count) - (char *)new);
-	dx_set_key(path, new, (struct dx_key *)&hash);
+	assert(old < iam_entry_shift(path, entries, count));
+	memmove(iam_entry_shift(path, new, 1), new,
+		(char *)iam_entry_shift(path, entries, count) - (char *)new);
+	dx_set_key(path, new, (struct iam_key *)&hash);
 	dx_set_block(path, new, block);
 	dx_set_count(entries, count + 1);
 }
@@ -1177,9 +1696,9 @@
 	struct super_block * sb;
 	struct dx_hash_info	hinfo;
 	u32 hash;
-	struct dx_path_compat cpath;
-	struct dx_path *path = &cpath.dpc_path;
-	struct dx_entry_compat dummy_dot = {
+	struct iam_path_compat cpath;
+	struct iam_path *path = &cpath.ipc_path;
+	struct iam_entry_compat dummy_dot = {
 		.block = 0
 	};
 	struct ext3_dir_entry_2 *de, *top;
@@ -1190,8 +1709,8 @@
 	const u8 *name = dentry->d_name.name;
 	struct inode *dir = dentry->d_parent->d_inode;
 
-	dx_path_compat_init(&cpath, dir);
-	
+	iam_path_compat_init(&cpath, dir);
+
 	sb = dir->i_sb;
 	/* NFS may look up ".." - look at dx_root directory block */
 	if (namelen > 2 || name[0] != '.'||(name[1] != '.' && name[1] != '\0')){
@@ -1199,13 +1718,15 @@
 		if (*err != 0)
 			return NULL;
 	} else {
-		path->dp_frame->bh = NULL;		/* for dx_path_fini() */
-		path->dp_frame->at = (void *)&dummy_dot;/* hack for zero entry*/
+		path->ip_frame->bh = NULL;		/* for iam_path_fini() */
+		path->ip_frame->at = (void *)&dummy_dot;/* hack for zero entry*/
 	}
 	hash = hinfo.hash;
 	do {
-		block = dx_get_block(path, path->dp_frame->at);
-		if (!(bh = ext3_bread (NULL,dir, block, 0, err)))
+		block = dx_get_block(path, path->ip_frame->at);
+		*err = path_descr(path)->id_node_read(path->ip_container, (iam_ptr_t)block,
+						     NULL, &bh);
+		if (*err != 0)
 			goto errout;
 		de = (struct ext3_dir_entry_2 *) bh->b_data;
 		top = (struct ext3_dir_entry_2 *) ((char *) de + sb->s_blocksize -
@@ -1220,7 +1741,7 @@
 				goto errout;
 			}
 			*res_dir = de;
-			dx_path_fini(path);
+			iam_path_fini(path);
 			return bh;
 		}
 		brelse (bh);
@@ -1238,7 +1759,7 @@
 	*err = -ENOENT;
 errout:
 	dxtrace(printk("%s not found\n", name));
-	dx_path_fini(path);
+	iam_path_fini(path);
 	return NULL;
 }
 #endif
@@ -1363,11 +1884,11 @@
 
 /* Allocate new node, and split leaf node @bh into it, inserting new pointer
  * into parent node identified by @frame */
-static struct ext3_dir_entry_2 *do_split(handle_t *handle, struct dx_path *path,
-			struct buffer_head **bh,struct dx_frame *frame,
+static struct ext3_dir_entry_2 *do_split(handle_t *handle, struct iam_path *path,
+			struct buffer_head **bh,struct iam_frame *frame,
 			struct dx_hash_info *hinfo, int *error)
 {
-	struct inode *dir = path->dp_object;
+	struct inode *dir = path_obj(path);
 	unsigned blocksize = dir->i_sb->s_blocksize;
 	unsigned count, continued;
 	struct buffer_head *bh2;
@@ -1553,9 +2074,9 @@
 	int		namelen = dentry->d_name.len;
 	struct buffer_head *bh2;
 	struct dx_root	*root;
-	struct dx_path_compat cpath;
-	struct dx_path *path = &cpath.dpc_path;
-	struct dx_entry *entries;
+	struct iam_path_compat cpath;
+	struct iam_path *path = &cpath.ipc_path;
+	struct iam_entry *entries;
 	struct ext3_dir_entry_2	*de, *de2;
 	char		*data1, *top;
 	unsigned	len;
@@ -1565,7 +2086,7 @@
 	u32		block;
 	struct fake_dirent *fde;
 
-	dx_path_compat_init(&cpath, dir);
+	iam_path_compat_init(&cpath, dir);
 	blocksize =  dir->i_sb->s_blocksize;
 	dxtrace(printk("Creating index\n"));
 	retval = ext3_journal_get_write_access(handle, bh);
@@ -1612,12 +2133,12 @@
 	hinfo.hash_version = root->info.hash_version;
 	hinfo.seed = EXT3_SB(dir->i_sb)->s_hash_seed;
 	ext3fs_dirhash(name, namelen, &hinfo);
-	path->dp_frame->entries = entries;
-	path->dp_frame->at = entries;
-	path->dp_frame->bh = bh;
+	path->ip_frame->entries = entries;
+	path->ip_frame->at = entries;
+	path->ip_frame->bh = bh;
 	bh = bh2;
-	de = do_split(handle, path, &bh, path->dp_frame, &hinfo, &retval);
-	dx_path_fini(path);
+	de = do_split(handle, path, &bh, path->ip_frame, &hinfo, &retval);
+	iam_path_fini(path);
 	if (!de)
 		return retval;
 
@@ -1698,12 +2219,12 @@
 static int ext3_dx_add_entry(handle_t *handle, struct dentry *dentry,
 			     struct inode *inode)
 {
-	struct dx_path_compat cpath;
-	struct dx_path *path = &cpath.dpc_path;
-	struct dx_param *param;
-	struct dx_frame *frame, *safe;
-	struct dx_entry *entries;   /* old block contents */
-	struct dx_entry *entries2;  /* new block contents */
+	struct iam_path_compat cpath;
+	struct iam_path *path = &cpath.ipc_path;
+	struct iam_descr *param;
+	struct iam_frame *frame, *safe;
+	struct iam_entry *entries;   /* old block contents */
+	struct iam_entry *entries2;  /* new block contents */
 	struct dx_hash_info hinfo;
 	struct buffer_head * bh;
 	struct buffer_head *bh_new[DX_MAX_TREE_HEIGHT] = {0};
@@ -1716,20 +2237,22 @@
 	int i;
 	size_t isize;
 
-	dx_path_compat_init(&cpath, dir);
-	param = path->dp_param;
+	iam_path_compat_init(&cpath, dir);
+	param = path_descr(path);
 
 	err = dx_probe(dentry, NULL, &hinfo, path);
 	if (err != 0)
 		return err;
-	frame = path->dp_frame;
+	frame = path->ip_frame;
 	entries = frame->entries;
 
 	/* XXX nikita: global serialization! */
 	isize = dir->i_size;
 
-	if (!(bh = ext3_bread(handle, dir,
-			      dx_get_block(path, frame->at), 0, &err)))
+	err = param->id_node_read(path->ip_container, 
+				  (iam_ptr_t)dx_get_block(path, 
+				  frame->at), handle, &bh);
+	if (err != 0)
 		goto cleanup;
 
 	BUFFER_TRACE(bh, "get_write_access");
@@ -1761,7 +2284,7 @@
 		       dx_get_count(entries), dx_get_limit(entries)));
 
 	/* What levels need split? */
-	for (nr_splet = 0; frame >= path->dp_frames &&
+	for (nr_splet = 0; frame >= path->ip_frames &&
 	     dx_get_count(frame->entries) == dx_get_limit(frame->entries);
 	     --frame, ++nr_splet) {
 		if (nr_splet == DX_MAX_TREE_HEIGHT) {
@@ -1778,7 +2301,7 @@
 	for (frame = safe + 1, i = 0; i < nr_splet; ++i, ++frame) {
 		bh_new[i] = ext3_append (handle, dir, &newblock[i], &err);
 		if (!bh_new[i] ||
-		    param->dpo_node_init(path, bh_new[i], 0) != 0)
+		    param->id_node_init(path->ip_container, bh_new[i], 0) != 0)
 			goto cleanup;
 		BUFFER_TRACE(frame->bh, "get_write_access");
 		err = ext3_journal_get_write_access(handle, frame->bh);
@@ -1786,7 +2309,7 @@
 			goto journal_error;
 	}
 	/* Add "safe" node to transaction too */
-	if (safe + 1 != path->dp_frames) {
+	if (safe + 1 != path->ip_frames) {
 		err = ext3_journal_get_write_access(handle, safe->bh);
 		if (err)
 			goto journal_error;
@@ -1800,12 +2323,12 @@
 
 		entries = frame->entries;
 		count = dx_get_count(entries);
-		idx = dx_entry_diff(path, frame->at, entries);
+		idx = iam_entry_diff(path, frame->at, entries);
 
 		bh2 = bh_new[i];
 		entries2 = dx_get_entries(path, bh2->b_data, 0);
 
-		if (frame == path->dp_frames) {
+		if (frame == path->ip_frames) {
 			/* splitting root node. Tricky point:
 			 *
 			 * In the "normal" B-tree we'd split root *and* add
@@ -1818,14 +2341,14 @@
 			 */
 			struct dx_root *root;
 			u8 indirects;
-			struct dx_frame *frames;
+			struct iam_frame *frames;
 
-			frames = path->dp_frames;
+			frames = path->ip_frames;
 			root = (struct dx_root *) frames->bh->b_data;
 			indirects = root->info.indirect_levels;
 			dxtrace(printk("Creating new root %d\n", indirects));
 			memcpy((char *) entries2, (char *) entries,
-			       count * dx_entry_size(path));
+			       count * iam_entry_size(path));
 			dx_set_limit(entries2, dx_node_limit(path));
 
 			/* Set up root */
@@ -1835,9 +2358,9 @@
 
 			/* Shift frames in the path */
 			memmove(frames + 2, frames + 1,
-				(sizeof path->dp_frames) - 2 * sizeof frames[0]);
+				(sizeof path->ip_frames) - 2 * sizeof frames[0]);
 			/* Add new access path frame */
-			frames[1].at = dx_entry_shift(path, entries2, idx);
+			frames[1].at = iam_entry_shift(path, entries2, idx);
 			frames[1].entries = entries = entries2;
 			frames[1].bh = bh2;
 			assert(dx_node_check(path, frame));
@@ -1853,22 +2376,22 @@
 			unsigned hash2;
 
 			dx_get_key(path,
-				   dx_entry_shift(path, entries, count1),
-				   (struct dx_key *)&hash2);
+				   iam_entry_shift(path, entries, count1),
+				   (struct iam_key *)&hash2);
 
 			dxtrace(printk("Split index %i/%i\n", count1, count2));
 
 			memcpy ((char *) entries2,
-				(char *) dx_entry_shift(path, entries, count1),
-				count2 * dx_entry_size(path));
+				(char *) iam_entry_shift(path, entries, count1),
+				count2 * iam_entry_size(path));
 			dx_set_count (entries, count1);
 			dx_set_count (entries2, count2);
 			dx_set_limit (entries2, dx_node_limit(path));
 
 			/* Which index block gets the new entry? */
 			if (idx >= count1) {
-				frame->at = dx_entry_shift(path, entries2,
-							   idx - count1);
+				frame->at = iam_entry_shift(path, entries2,
+							    idx - count1);
 				frame->entries = entries = entries2;
 				swap(frame->bh, bh2);
 				bh_new[i] = bh2;
@@ -1903,7 +2426,7 @@
 	}
 	if (err)
 		inode->i_size = isize;
-	dx_path_fini(path);
+	iam_path_fini(path);
 	return err;
 }
 #endif
